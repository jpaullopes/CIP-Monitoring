# SensorFlow Server - InfluxDB Edition üöÄ

[![Python](https://img.shields.io/badge/Python-3.11+-green.svg)](https://python.org)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.95+-blue)](https://fastapi.tiangolo.com/)
[![InfluxDB](https://img.shields.io/badge/InfluxDB-v3.0+-orange)](https://influxdata.com/)
[![Version](https://img.shields.io/badge/version-2.1.0-brightgreen)](https://github.com/jpaullopes/sensorflow-server-ethernet)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

**SensorFlow Server - InfluxDB Edition** √© uma solu√ß√£o backend moderna e escal√°vel desenvolvida em Python/FastAPI para gerenciamento de dados de sensores em tempo real. Oferece persist√™ncia em **InfluxDB v3 com consultas SQL nativas**, visualiza√ß√£o via Grafana, e comunica√ß√£o bidirecional via WebSockets.

**Principais Diferenciais:**
- üèóÔ∏è **Arquitetura Clean**: Organiza√ß√£o modular seguindo princ√≠pios de Clean Architecture
- üóÑÔ∏è **InfluxDB v3**: Banco de dados de s√©ries temporais com suporte SQL nativo
- üìä **Consultas SQL**: Queries diretas no InfluxDB v3 via API REST
- üîÑ **Real-time**: WebSockets para streaming de dados em tempo real
- üõ°Ô∏è **Seguran√ßa**: Autentica√ß√£o por API Key com controle granular

**Compatibilidade:** Este servidor funciona tanto com dispositivos conectados via **WiFi** quanto com **m√≥dulos Ethernet** (como W5500 ou W5100) sem necessidade de altera√ß√µes no c√≥digo.

---

## √çndice

- [Funcionalidades](#funcionalidades)
- [Arquitetura](#-arquitetura)  
- [Tecnologias](#-tecnologias)
- [Instala√ß√£o](#-instala√ß√£o)
- [API Endpoints](#-api-endpoints)
- [Consultas SQL](#-consultas-sql-influxdb-v3)
- [Integra√ß√£o Grafana](#-integra√ß√£o-grafana)
- [Seguran√ßa](#-seguran√ßa)
- [Monitoramento](#-monitoramento)
- [Desenvolvimento](#-desenvolvimento)
- [Licen√ßa](#-licen√ßa)

## üåü Funcionalidades

### ‚ú® Core Features
- **API REST Segura**: Endpoints protegidos por API Key para recep√ß√£o de dados de sensores
- **WebSocket em Tempo Real**: Distribui√ß√£o instant√¢nea de dados para clientes conectados
- **InfluxDB v3**: Armazenamento de s√©ries temporais com **consultas SQL nativas**
- **Health Monitoring**: Endpoints de sa√∫de para monitoramento da aplica√ß√£o
- **Visualiza√ß√£o com Grafana**: Dashboards personaliz√°veis para an√°lise de dados

### üèóÔ∏è Arquitetura Moderna
- **Clean Architecture**: Separa√ß√£o clara entre dom√≠nio, aplica√ß√£o e infraestrutura
- **Inje√ß√£o de Depend√™ncias**: Desacoplamento entre componentes
- **Configura√ß√£o Externa**: Vari√°veis de ambiente para todas as configura√ß√µes
- **Logs Estruturados**: Sistema avan√ßado com n√≠veis e formata√ß√£o colorida

### üîí Seguran√ßa & Performance  
- **Autentica√ß√£o Dupla**: API Keys independentes para HTTP e WebSocket
- **Limita√ß√£o de Conex√µes**: Controle granular de conex√µes por API Key
- **Valida√ß√£o de Dados**: Schemas Pydantic para valida√ß√£o autom√°tica
- **SQL Injection Protection**: Consultas seguras via cliente oficial InfluxDB

### üöÄ DevOps & Deployment
- **Docker Compose**: Stack completa com orquestra√ß√£o de servi√ßos
- **Healthchecks**: Verifica√ß√£o autom√°tica de sa√∫de dos containers
- **Compatibilidade Ethernet**: Suporte nativo para m√≥dulos W5500 e W5100
- **CLI Tools**: Comandos diretos para intera√ß√£o com InfluxDB v3

## üèóÔ∏è Arquitetura

O projeto segue **Clean Architecture** com separa√ß√£o clara de responsabilidades em camadas:

```plaintext
sensorflow-server-ethernet/
‚îú‚îÄ‚îÄ app/                           # üöÄ Camada de Aplica√ß√£o
‚îÇ   ‚îú‚îÄ‚îÄ main.py                   # Entry point FastAPI
‚îÇ   ‚îú‚îÄ‚îÄ lifecycle.py              # Hooks de startup/shutdown
‚îÇ   ‚îî‚îÄ‚îÄ dependencies.py           # Inje√ß√£o de depend√™ncias
‚îú‚îÄ‚îÄ src/                          # üì¶ C√≥digo fonte modular
‚îÇ   ‚îú‚îÄ‚îÄ api/v1/                   # üõ£Ô∏è Camada de Interface (Routers)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ routers/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ temperature.py    # Endpoints de sensores
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ websocket.py      # WebSocket real-time
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ health.py         # Health monitoring
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ query.py          # Consultas SQL InfluxDB
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ schemas/
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ temperature.py    # Modelos Pydantic
‚îÇ   ‚îú‚îÄ‚îÄ core/                     # üíé Camada de Dom√≠nio
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ models/               # Entidades de neg√≥cio
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ services/             # L√≥gica de dom√≠nio
‚îÇ   ‚îî‚îÄ‚îÄ infrastructure/           # üîß Camada de Infraestrutura
‚îÇ       ‚îú‚îÄ‚îÄ config/
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ settings.py       # Configura√ß√µes da aplica√ß√£o
‚îÇ       ‚îú‚îÄ‚îÄ influx/
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ client.py         # Cliente InfluxDB v3
‚îÇ       ‚îú‚îÄ‚îÄ logging/
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ config.py         # Sistema de logs
‚îÇ       ‚îú‚îÄ‚îÄ security/
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ api_key.py        # Autentica√ß√£o API Key
‚îÇ       ‚îî‚îÄ‚îÄ websocket/
‚îÇ           ‚îî‚îÄ‚îÄ manager.py        # Gerenciamento WebSocket
‚îú‚îÄ‚îÄ docker-compose.yml            # üê≥ Orquestra√ß√£o dos servi√ßos
‚îú‚îÄ‚îÄ Dockerfile                    # üì¶ Defini√ß√£o da imagem
‚îú‚îÄ‚îÄ requirements.txt              # üìã Depend√™ncias Python
‚îî‚îÄ‚îÄ grafana/                      # üìä Configura√ß√£o Grafana
    ‚îî‚îÄ‚îÄ provisioning/
        ‚îú‚îÄ‚îÄ datasources/          # InfluxDB datasource
        ‚îî‚îÄ‚îÄ dashboards/           # Dashboards pr√©-configurados
```

### üéØ Princ√≠pios Arquiteturais

- **Separation of Concerns**: Cada camada tem responsabilidades bem definidas
- **Dependency Inversion**: Abstra√ß√µes n√£o dependem de implementa√ß√µes
- **Single Responsibility**: Cada m√≥dulo tem uma √∫nica raz√£o para mudar
- **Interface Segregation**: Interfaces espec√≠ficas para cada cliente

## üõ†Ô∏è Tecnologias

### Backend & Framework
- **Python**: 3.11+
- **FastAPI**: Framework moderno e r√°pido com documenta√ß√£o autom√°tica
- **Uvicorn**: Servidor ASGI de alta performance
- **Pydantic**: Valida√ß√£o de dados e serializa√ß√£o

### Banco de Dados & S√©ries Temporais
- **InfluxDB v3**: Banco de dados de s√©ries temporais com SQL nativo
- **influxdb_client_3**: Cliente Python oficial para InfluxDB v3

### Comunica√ß√£o & Real-time
- **WebSockets**: Comunica√ß√£o bidirecional em tempo real
- **API REST**: Endpoints HTTP para ingest√£o de dados

### Visualiza√ß√£o & Monitoramento
- **Grafana OSS**: Dashboards e visualiza√ß√£o de dados
- **Health Endpoints**: Monitoramento da sa√∫de da aplica√ß√£o

### DevOps & Deployment
- **Docker**: Containeriza√ß√£o da aplica√ß√£o
- **Docker Compose**: Orquestra√ß√£o multi-container
- **Dockerfile**: Build automatizado da imagem

### Logging & Configura√ß√£o
- **Pydantic Settings**: Gest√£o de configura√ß√µes via env vars
- **Logging**: Sistema de logs estruturado e colorido

## üöÄ Instala√ß√£o

### Pr√©-requisitos

- [Docker](https://docs.docker.com/get-docker/) (v20.10+)
- [Docker Compose](https://docs.docker.com/compose/install/) (v2.0+)

### ‚ö° Configura√ß√£o R√°pida

1. **Clone o reposit√≥rio**

```bash
git clone https://github.com/jpaullopes/sensorflow-server-ethernet.git
cd sensorflow-server-ethernet
```

2. **Configure o ambiente**

Crie um arquivo `.env` na raiz:

```dotenv
# üîê API Keys de Seguran√ßa
API_KEY=sua_chave_http_secreta_aqui
API_KEY_WS=sua_chave_websocket_secreta_aqui

# üóÑÔ∏è InfluxDB v3 Configuration
INFLUX_HOST=http://influxdb3-core:8181
INFLUX_TOKEN=apiv3_Q7UBMofejrm2UKcSBxcgZWsrq0F9yBplA1rOJcPJRYY8xaGV0H4yYLCQ3djH9f4tqPpVQUQGT6UmH2TuHJAV9Q==
INFLUX_DATABASE=sensores

# üîó Conex√µes & Limites  
MAX_WS_CONNECTIONS_PER_KEY=10

# üìä Grafana
GF_SECURITY_ADMIN_PASSWORD=admin123
```

3. **Inicie a stack completa**

```bash
# Iniciar todos os servi√ßos
docker-compose up -d

# Verificar status dos containers
docker-compose ps

# Acompanhar logs em tempo real
docker-compose logs -f api
```

4. **Acesse os servi√ßos**

| Servi√ßo    | URL                                        | Credenciais      |
|------------|--------------------------------------------|------------------|
| **API**    | [http://localhost:8000](http://localhost:8000) | API Key via header |
| **Docs**   | [http://localhost:8000/docs](http://localhost:8000/docs) | Interface Swagger |
| **InfluxDB**| [http://localhost:8181](http://localhost:8181) | Token via env    |
| **Grafana** | [http://localhost:3000](http://localhost:3000) | admin/admin123  |

### üîß Comandos √öteis

```bash
# Rebuild apenas a API (ap√≥s mudan√ßas no c√≥digo)
docker-compose up --build -d api

# Verificar logs espec√≠ficos
docker-compose logs api        # Logs da API
docker-compose logs influxdb3-core  # Logs do InfluxDB
docker-compose logs grafana    # Logs do Grafana

# Parar todos os servi√ßos
docker-compose down

# Limpar volumes (cuidado: apaga dados!)
docker-compose down -v
```

## üõ£Ô∏è API Endpoints

### üì° Recep√ß√£o de Dados de Sensores

**POST** `/api/v1/temperature_reading`

Endpoint principal para envio de dados de sensores, protegido por API Key.

**Headers necess√°rios:**
- `X-API-Key`: Chave de autentica√ß√£o para API
- `Content-Type`: application/json

**Payload:**
```json
{
  "temperature": 25.5,      // Temperatura em Celsius
  "humidity": 60.2,         // Umidade relativa (%)
  "pressure": 1012.5,       // Press√£o atmosf√©rica (hPa)  
  "sensor_id": "sensor_001" // ID √∫nico do sensor
}
```

**Resposta (201 Created):**
```json
{
  "id": 123,
  "temperature": 25.5,
  "humidity": 60.2,
  "pressure": 1012.5,
  "date_recorded": "2025-08-16",
  "time_recorded": "14:30:45",
  "sensor_id": "sensor_001",
  "client_ip": "192.168.1.100"
}
```

**Exemplo cURL:**
```bash
curl -X POST "http://localhost:8000/api/v1/temperature_reading" \
  -H "X-API-Key: sua_chave_http_secreta" \
  -H "Content-Type: application/json" \
  -d '{
    "temperature": 25.5,
    "humidity": 60.2, 
    "pressure": 1012.5,
    "sensor_id": "sensor_001"
  }'
```

### üè• Health Monitoring

**GET** `/api/v1/health`

Endpoint completo de sa√∫de da aplica√ß√£o com informa√ß√µes detalhadas.

**Resposta:**
```json
{
  "status": "healthy",
  "timestamp": "2025-08-16T15:30:45.123Z",
  "version": "2.1.0",
  "services": {
    "influxdb": "connected",
    "websocket_manager": "active"
  },
  "uptime_seconds": 3600
}
```

**GET** `/api/v1/ping`

Endpoint simples para verifica√ß√£o r√°pida (health check).

**Resposta:**
```json
{
  "status": "ok",
  "message": "SensorFlow API is running"
}
```

### üîç Consulta de Dados

**GET** `/api/v1/sensor/{sensor_id}/latest`

Busca o √∫ltimo registro de um sensor espec√≠fico.

**Exemplo:**
```bash
curl -H "X-API-Key: sua_chave" \
  "http://localhost:8000/api/v1/sensor/sensor_001/latest"
```

### üåê WebSocket para Tempo Real

**WebSocket** `/ws/sensor_updates?api-key=sua_chave_websocket`

Conex√£o WebSocket para receber dados em tempo real conforme chegam na API.

**Par√¢metros de Query:**
- `api-key`: Chave de autentica√ß√£o para WebSocket (obrigat√≥rio)

**Exemplo JavaScript:**
```javascript
const ws = new WebSocket('ws://localhost:8000/ws/sensor_updates?api-key=sua_chave_websocket');

ws.onopen = function() {
    console.log('üîå Conectado ao WebSocket');
};

ws.onmessage = function(event) {
    const data = JSON.parse(event.data);
    console.log('üì° Novos dados:', data);
    // Atualizar dashboard em tempo real
};

ws.onclose = function() {
    console.log('üîå Desconectado do WebSocket');
};
```

**Dados recebidos em tempo real:**
```json
{
  "temperature": 25.5,
  "humidity": 60.2, 
  "pressure": 1012.5,
  "sensor_id": "sensor_001",
  "timestamp": "2025-08-16T15:30:45.123Z"
}
```

## üóÑÔ∏è Consultas SQL - InfluxDB v3

Uma das principais vantagens desta vers√£o √© o **suporte nativo a SQL** no InfluxDB v3.

### üîß Via API REST

**POST** `/api/v1/query`

Execute consultas SQL diretamente no InfluxDB v3 via API.

**Headers:**
- `X-API-Key`: Chave de autentica√ß√£o
- `Content-Type`: application/json

**Payload:**
```json
{
  "query": "SELECT * FROM sensor_readings ORDER BY time DESC LIMIT 10"
}
```

**Exemplo cURL:**
```bash
curl -X POST "http://localhost:8000/api/v1/query" \
  -H "X-API-Key: sua_chave_http_secreta" \
  -H "Content-Type: application/json" \
  -d '{"query": "SELECT * FROM sensor_readings ORDER BY time DESC LIMIT 10"}'
```

### üíª Via CLI (Docker)

Execute consultas SQL diretamente no container InfluxDB:

```bash
# Listar 10 registros mais recentes
docker-compose exec influxdb3-core influxdb3 query \
  --token "$INFLUX_TOKEN" \
  --database "sensores" \
  "SELECT * FROM sensor_readings ORDER BY time DESC LIMIT 10"

# Contar total de registros
docker-compose exec influxdb3-core influxdb3 query \
  --token "$INFLUX_TOKEN" \
  --database "sensores" \
  "SELECT COUNT(*) FROM sensor_readings"

# Dados de um sensor espec√≠fico nas √∫ltimas 24h
docker-compose exec influxdb3-core influxdb3 query \
  --token "$INFLUX_TOKEN" \
  --database "sensores" \
  "SELECT * FROM sensor_readings 
   WHERE sensor_id = 'sensor_001' 
   AND time > now() - interval '24 hours'"

# M√©dia de temperatura por sensor
docker-compose exec influxdb3-core influxdb3 query \
  --token "$INFLUX_TOKEN" \
  --database "sensores" \
  "SELECT sensor_id, AVG(temperature) as avg_temp 
   FROM sensor_readings 
   GROUP BY sensor_id"
```

### üìä Estrutura dos Dados

Os dados s√£o armazenados na tabela `sensor_readings` com a seguinte estrutura:

| Coluna        | Tipo      | Descri√ß√£o                    |
|---------------|-----------|------------------------------|
| `time`        | Timestamp | Momento da leitura (autom√°tico) |
| `sensor_id`   | String    | Identificador √∫nico do sensor |
| `client_ip`   | String    | IP do cliente que enviou     |
| `temperature` | Float     | Temperatura em Celsius       |
| `humidity`    | Float     | Umidade relativa (%)         |
| `pressure`    | Float     | Press√£o atmosf√©rica (hPa)    |

### üîç Consultas √öteis

```sql
-- üìà Tend√™ncia de temperatura nas √∫ltimas 2 horas
SELECT 
  time,
  sensor_id,
  temperature,
  LAG(temperature) OVER (PARTITION BY sensor_id ORDER BY time) as prev_temp
FROM sensor_readings 
WHERE time > now() - interval '2 hours'
ORDER BY time DESC;

-- üå°Ô∏è Sensores com temperatura cr√≠tica
SELECT DISTINCT sensor_id, MAX(temperature) as max_temp
FROM sensor_readings 
WHERE temperature > 30
GROUP BY sensor_id;

-- üìä Estat√≠sticas por sensor (√∫ltima hora)
SELECT 
  sensor_id,
  COUNT(*) as readings_count,
  AVG(temperature) as avg_temp,
  MIN(temperature) as min_temp,
  MAX(temperature) as max_temp,
  AVG(humidity) as avg_humidity
FROM sensor_readings 
WHERE time > now() - interval '1 hour'
GROUP BY sensor_id;
```

## üìä Integra√ß√£o Grafana

O SensorFlow Server implementa provisionamento autom√°tico do Grafana com **InfluxDB v3** como fonte de dados, permitindo visualiza√ß√£o imediata dos dados.

### üîß Provisionamento Autom√°tico

O sistema configura automaticamente:

- ‚úÖ **Fonte de dados InfluxDB v3** pr√©-configurada
- ‚úÖ **Conex√£o segura** com token e database via vari√°veis de ambiente
- ‚úÖ **SQL Query Support** para consultas diretas nas tabelas
- ‚úÖ **Dashboards pr√©-configurados** para monitoramento de sensores

### üé® Cria√ß√£o de Dashboards

1. **Acesse o Grafana**: [http://localhost:3000](http://localhost:3000)
2. **Login**: admin / admin123 (conforme configurado no .env)
3. **Novo Dashboard**: "+" ‚Üí "Dashboard" ‚Üí "Add new panel"
4. **Fonte de dados**: "InfluxDB v3 Sensores" (pr√©-configurada)

### üîç Queries SQL para Dashboards

**Temperatura em Tempo Real:**
```sql
SELECT 
  time as "time",
  temperature,
  sensor_id
FROM sensor_readings 
WHERE $__timeFilter(time)
  AND sensor_id = '$sensor_id'
ORDER BY time DESC
```

**M√∫ltiplos Sensores (Series):**
```sql
SELECT 
  time as "time",
  temperature,
  sensor_id as "metric"  
FROM sensor_readings 
WHERE $__timeFilter(time)
GROUP BY sensor_id
ORDER BY time DESC
```

**Estat√≠sticas por Per√≠odo:**
```sql
SELECT 
  time_bucket('5 minutes', time) as "time",
  sensor_id,
  AVG(temperature) as avg_temperature,
  AVG(humidity) as avg_humidity,
  AVG(pressure) as avg_pressure
FROM sensor_readings 
WHERE $__timeFilter(time)
GROUP BY time_bucket('5 minutes', time), sensor_id
ORDER BY time
```

**Status de Conex√£o dos Sensores:**
```sql
SELECT 
  sensor_id,
  MAX(time) as last_seen,
  COUNT(*) as total_readings
FROM sensor_readings 
WHERE $__timeFilter(time)
GROUP BY sensor_id
```

### üìà Tipos de Visualiza√ß√£o Recomendados

| M√©trica | Tipo de Painel | Query |
|---------|----------------|-------|
| **Temperatura** | Time Series | `SELECT time, temperature, sensor_id FROM sensor_readings` |
| **Umidade** | Gauge | `SELECT AVG(humidity) FROM sensor_readings WHERE time > now() - interval '1 hour'` |
| **Press√£o** | Stat | `SELECT pressure FROM sensor_readings ORDER BY time DESC LIMIT 1` |
| **Status Sensores** | Table | `SELECT sensor_id, MAX(time) as last_update FROM sensor_readings GROUP BY sensor_id` |

### üö® Alertas e Notifica√ß√µes

Configure alertas baseados em thresholds:

```sql
-- Alerta de temperatura alta
SELECT 
  sensor_id,
  temperature,
  time
FROM sensor_readings 
WHERE temperature > 35
  AND time > now() - interval '5 minutes'
```

### üîß Vari√°veis de Dashboard

Crie vari√°veis para dashboards din√¢micos:

**Variable `sensor_id`:**
```sql
SELECT DISTINCT sensor_id FROM sensor_readings
```

**Variable `time_range`:**
- Custom: `1h,6h,24h,7d`

Isso permite dashboards interativos onde o usu√°rio pode filtrar por sensor e per√≠odo de tempo.

## üõ°Ô∏è Seguran√ßa

O SensorFlow Server implementa m√∫ltiplas camadas de seguran√ßa empresariais:

### üîê Autentica√ß√£o por API Key
- **Chaves Independentes**: Separa√ß√£o entre HTTP (`API_KEY`) e WebSocket (`API_KEY_WS`)
- **Headers Seguros**: Autentica√ß√£o via `X-API-Key` header
- **Valida√ß√£o Autom√°tica**: Middleware de autentica√ß√£o em todos os endpoints protegidos

### üöß Controle de Acesso
- **Limita√ß√£o de Conex√µes**: M√°ximo configur√°vel de conex√µes WebSocket por API Key
- **Valida√ß√£o de Origem**: Tracking de IP do cliente para auditoria
- **Sanitiza√ß√£o de Inputs**: Valida√ß√£o autom√°tica via schemas Pydantic

### üîí Prote√ß√µes Implementadas
- **SQL Injection**: Consultas preparadas via cliente oficial InfluxDB
- **CORS**: Configura√ß√£o de Cross-Origin Resource Sharing
- **Rate Limiting**: Preven√ß√£o de abuso de endpoints
- **Logs de Auditoria**: Rastreamento detalhado de todas as opera√ß√µes

### üìã Configura√ß√£o de Seguran√ßa

```dotenv
# Chaves de 32+ caracteres recomendadas
API_KEY=sua_chave_http_muito_secreta_e_longa_aqui
API_KEY_WS=sua_chave_websocket_muito_secreta_e_longa_aqui

# Controle de conex√µes
MAX_WS_CONNECTIONS_PER_KEY=10

# InfluxDB Token seguro (gerado automaticamente)
INFLUX_TOKEN=apiv3_Q7UBMofejrm2UKcSBxcgZWsrq0F9yBplA1rOJcPJRYY...
```

## üìà Monitoramento

### üè• Health Endpoints

- **`GET /api/v1/health`**: Status completo da aplica√ß√£o
- **`GET /api/v1/ping`**: Verifica√ß√£o r√°pida de sa√∫de

### üìä Logs de Aplica√ß√£o

```bash
# Logs em tempo real
docker-compose logs -f api

# Logs espec√≠ficos por servi√ßo
docker-compose logs influxdb3-core  # InfluxDB
docker-compose logs grafana         # Grafana

# Filtrar por n√≠vel de log
docker-compose logs api | grep ERROR
docker-compose logs api | grep INFO
```

### üìà M√©tricas Dispon√≠veis

- **Lat√™ncia de Requests**: Tempo de processamento de cada endpoint
- **Taxa de Ingest√£o**: Dados recebidos por minuto/hora
- **Conex√µes WebSocket**: N√∫mero de conex√µes ativas
- **Health Status**: Estado de sa√∫de do InfluxDB e demais servi√ßos
- **Uso de Recursos**: Memory usage, CPU, Network I/O

### üö® Alertas e Monitoramento

**Via Logs:**
```bash
# Monitorar erros cr√≠ticos
docker-compose logs api | grep "ERROR\|CRITICAL"

# Monitorar conex√µes WebSocket
docker-compose logs api | grep "WebSocket"

# Monitorar ingest√£o de dados
docker-compose logs api | grep "temperature_reading"
```

**Via InfluxDB (Queries de Monitoramento):**
```sql
-- Taxa de ingest√£o por hora
SELECT 
  date_trunc('hour', time) as hour,
  COUNT(*) as readings_per_hour
FROM sensor_readings 
WHERE time > now() - interval '24 hours'
GROUP BY hour
ORDER BY hour;

-- Sensores inativos (sem dados h√° mais de 1 hora)
SELECT DISTINCT sensor_id, MAX(time) as last_reading
FROM sensor_readings 
GROUP BY sensor_id
HAVING MAX(time) < now() - interval '1 hour';
```

## üßë‚Äçüíª Desenvolvimento

### üéØ Princ√≠pios de Design

O SensorFlow Server segue **Clean Architecture** e princ√≠pios SOLID:

- **üîÑ Separation of Concerns**: Cada camada tem responsabilidades bem definidas
- **üì¶ Dependency Inversion**: Abstra√ß√µes n√£o dependem de implementa√ß√µes
- **üéØ Single Responsibility**: Cada m√≥dulo tem uma √∫nica raz√£o para mudar
- **üîß Interface Segregation**: Interfaces espec√≠ficas para cada necessidade
- **üîÄ Open/Closed**: Aberto para extens√£o, fechado para modifica√ß√£o

### üèóÔ∏è Estrutura do C√≥digo

```plaintext
src/
‚îú‚îÄ‚îÄ api/v1/                  # üåê Interface Layer (Controllers)
‚îÇ   ‚îú‚îÄ‚îÄ routers/            # FastAPI routers
‚îÇ   ‚îî‚îÄ‚îÄ schemas/            # Request/Response models
‚îú‚îÄ‚îÄ core/                   # üíé Domain Layer (Business Logic)
‚îÇ   ‚îú‚îÄ‚îÄ models/            # Domain entities
‚îÇ   ‚îî‚îÄ‚îÄ services/          # Business rules
‚îî‚îÄ‚îÄ infrastructure/        # üîß Infrastructure Layer (External)
    ‚îú‚îÄ‚îÄ config/           # Configuration management
    ‚îú‚îÄ‚îÄ influx/           # Database client
    ‚îú‚îÄ‚îÄ logging/          # Logging system
    ‚îú‚îÄ‚îÄ security/         # Authentication
    ‚îî‚îÄ‚îÄ websocket/        # WebSocket manager
```

### üîß Desenvolvimento Local

#### Configurar Ambiente de Desenvolvimento:

```bash
# 1. Clone e entre no diret√≥rio
git clone https://github.com/jpaullopes/sensorflow-server-ethernet.git
cd sensorflow-server-ethernet

# 2. Crie ambiente virtual Python
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate     # Windows

# 3. Instale depend√™ncias
pip install -r requirements.txt

# 4. Configure .env para desenvolvimento
cp .env.example .env      # Ajuste as vari√°veis
```

#### Executar em Modo Desenvolvimento:

```bash
# Apenas InfluxDB (desenvolvimento da API)
docker-compose up -d influxdb3-core

# API em desenvolvimento (hot reload)
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000

# Todos os servi√ßos
docker-compose up -d
```

### üß™ Testes

```bash
# Testes unit√°rios
python -m pytest tests/

# Testes com coverage
python -m pytest tests/ --cov=src

# Testes de integra√ß√£o
python -m pytest tests/integration/

# Linting e formata√ß√£o
flake8 src/
black src/
isort src/
```

### üì¶ Extensibilidade

#### Adicionar Novo Tipo de Sensor:

1. **Schema** (src/api/v1/schemas/):
```python
# new_sensor.py
from pydantic import BaseModel

class NewSensorReading(BaseModel):
    sensor_id: str
    custom_value: float
    # ... outros campos
```

2. **Router** (src/api/v1/routers/):
```python
# new_sensor.py
from fastapi import APIRouter

router = APIRouter()

@router.post("/new_sensor_reading")
async def receive_data(data: NewSensorReading):
    # ... l√≥gica de processamento
```

3. **Registrar Router** (src/api/v1/routers/__init__.py):
```python
from .new_sensor import router as new_sensor_router

api_v1_router.include_router(new_sensor_router, tags=["new_sensor"])
```

#### Adicionar Nova Funcionalidade:

1. **Service** (src/core/services/):
```python
# analytics.py
class AnalyticsService:
    def calculate_trends(self, sensor_data):
        # L√≥gica de neg√≥cio
        pass
```

2. **Infrastructure** (src/infrastructure/):
```python
# external_api.py  
class ExternalAPIClient:
    def send_alert(self, data):
        # Integra√ß√£o externa
        pass
```

### ü§ù Contribui√ß√£o

#### Fluxo de Contribui√ß√£o:

1. **Fork** do reposit√≥rio
2. **Branch** para sua feature: `git checkout -b feature/nova-funcionalidade`
3. **Implementar** com testes apropriados
4. **Documentar** altera√ß√µes no README (se necess√°rio)
5. **Pull Request** com descri√ß√£o detalhada

#### Padr√µes de C√≥digo:

- **Docstrings**: Google Style para todas as fun√ß√µes
- **Type Hints**: Obrigat√≥rio para par√¢metros e retornos
- **Error Handling**: Try/catch com logs apropriados
- **Testes**: Cobertura m√≠nima de 80%

#### Exemplo de Implementa√ß√£o:

```python
from typing import Optional
from src.infrastructure.influx.client import InfluxClient

class SensorService:
    """Service para processamento de dados de sensores."""
    
    def __init__(self, influx_client: InfluxClient):
        """
        Args:
            influx_client: Cliente InfluxDB para persist√™ncia.
        """
        self.influx_client = influx_client
    
    async def process_reading(self, reading: dict) -> Optional[dict]:
        """
        Processa leitura de sensor e persiste no InfluxDB.
        
        Args:
            reading: Dados do sensor validados.
            
        Returns:
            Dados processados ou None em caso de erro.
            
        Raises:
            ProcessingError: Se falhar no processamento.
        """
        try:
            # L√≥gica de processamento
            result = await self.influx_client.write_data(reading)
            return result
        except Exception as e:
            logger.error(f"Erro ao processar leitura: {e}")
            raise ProcessingError(f"Falha no processamento: {e}")
```

### üîç Debug e Troubleshooting

```bash
# Logs detalhados da aplica√ß√£o
docker-compose logs -f api

# Acesso ao container para debug
docker-compose exec api /bin/bash

# Verificar conectividade InfluxDB
docker-compose exec api python -c "
from src.infrastructure.influx.client import get_influx_client
client = get_influx_client()
print('InfluxDB conectado:', client is not None)
"

# Testar endpoints manualmente
curl -H "X-API-Key: sua_chave" http://localhost:8000/api/v1/health
```

## Servi√ßos

| Servi√ßo    | Porta | Descri√ß√£o                  | URL Local                   |
|------------|-------|----------------------------|----------------------------|
| **API**    | 8000  | Backend FastAPI            | http://localhost:8000      |
| **DB**     | 5432  | Banco de dados PostgreSQL  | postgresql://localhost:5432 |
| **Grafana**| 3000  | Visualiza√ß√£o de dados      | http://localhost:3000      |

## Licen√ßa

Este projeto est√° licenciado sob os termos da licen√ßa MIT - veja o arquivo [LICENSE](LICENSE) para detalhes.


